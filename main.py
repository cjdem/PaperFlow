import os
import json
import re
import fitz  # PyMuPDF
import asyncio
from dotenv import load_dotenv
from sqlalchemy.orm import Session
from db_models import Paper, Session as DBSession
from json_repair import repair_json
from llm_pool import llm_manager
from log_service import workflow_logger, get_logger

logger = get_logger("main")

load_dotenv()

# ================= å·¥å…·å‡½æ•° =================

def normalize_title(title):
    if not title: return ""
    return re.sub(r'[^a-zA-Z0-9]', '', title).lower()

def extract_pdf_content(file_path):
    logger.debug(f"æ­£åœ¨è¯»å– PDF: {file_path}")
    try:
        doc = fitz.open(file_path)
        full_text = ""
        for page in doc:
            full_text += page.get_text()
        
        if len(full_text) < 100:
            logger.warning("æå–å†…å®¹è¿‡å°‘ï¼Œå¯èƒ½æ˜¯æ‰«æä»¶")
            return None, None
            
        head_text = full_text[:15000]
        return head_text, full_text
    except Exception as e:
        logger.error(f"PDF è¯»å–å¤±è´¥: {e}")
        return None, None

# ================= LLM ä»»åŠ¡ =================

async def task_extract_metadata(text):
    if not text: return None
    logger.info("è¯·æ±‚å…ƒæ•°æ®æå– (Pool: Metadata)")
    
    def validate_json(content):
        return "title" in content and len(content) > 20

    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦æœ¯æ–‡çŒ®è§£æåŠ©æ‰‹ã€‚è¯·ä»è®ºæ–‡ç‰‡æ®µä¸­æå–å…ƒæ•°æ®ã€‚
    
    ã€é‡è¦æç¤ºã€‘ï¼š
    1. **ä½œè€…æå–**ï¼šä½œè€…é€šå¸¸ä½äºæ ‡é¢˜æ­£ä¸‹æ–¹ã€‚å¦‚æœåå­—åé¢å¸¦æœ‰æ•°å­—è§’æ ‡ï¼Œè¯·å»é™¤æ•°å­—ã€‚
    2. **æ ¼å¼**ï¼šauthors å­—æ®µè¯·è¿”å›ä¸€ä¸ª**å­—ç¬¦ä¸²**ï¼Œå¤šä¸ªä½œè€…ç”¨è‹±æ–‡é€—å·æ‹¼æ¥ã€‚
    
    ã€è¾“å‡º JSON å­—æ®µã€‘ï¼š
    - title (String): è‹±æ–‡æ ‡é¢˜
    - title_cn (String): ä¸­æ–‡ç¿»è¯‘æ ‡é¢˜
    - authors (String): ä½œè€…åˆ—è¡¨å­—ç¬¦ä¸²
    - journal (String): æœŸåˆŠå
    - year (Integer): å¹´ä»½
    - abstract_en (String): è‹±æ–‡æ‘˜è¦åŸæ–‡
    - abstract (String): ä¸­æ–‡æ‘˜è¦ç¿»è¯‘

    ã€è®ºæ–‡ç‰‡æ®µã€‘ï¼š
    {text} ... 
    """
    
    try:
        response = await llm_manager.chat(
            pool_name="metadata",
            messages=[{"role": "user", "content": prompt}],
            response_format={"type": "json_object"},
            temperature=0.1,
            validator=validate_json
        )
        content = response.choices[0].message.content
        parsed_json = json.loads(repair_json(content))
        
        if isinstance(parsed_json.get('authors'), list):
            parsed_json['authors'] = ", ".join(parsed_json['authors'])
            
        logger.info(f"å…ƒæ•°æ®æå–æˆåŠŸ: {parsed_json.get('title_cn')}")
        return parsed_json

    except Exception as e:
        logger.error(f"Metadata ä»»åŠ¡å¤±è´¥: {e}")
        raise e

async def task_analyze_paper(full_text):
    if not full_text: return "æ— å†…å®¹"
    logger.info("è¯·æ±‚æ·±åº¦åˆ†æ (Pool: Analysis)")
    
    input_text = full_text

    def validate_analysis(content):
        if len(content) < 100: return False
        bad_words = ["Bad Gateway", "upstream connect error", "Service Unavailable", "<html>"]
        for w in bad_words:
            if w.lower() in content.lower(): return False
        return True

    # 1. å®šä¹‰ System Prompt (èº«ä»½è®¾å®š)
    system_prompt = """
    ä½ æ˜¯ä¸€ä½ä¸¥è°¨çš„å­¦æœ¯ç ”ç©¶å‘˜ã€‚è¯·æ ¹æ®ç”¨æˆ·æä¾›çš„è®ºæ–‡å…¨æ–‡ï¼Œæ’°å†™ä¸€ä»½ã€å…¨é¢ã€ç³»ç»Ÿã€æ‰¹åˆ¤æ€§ã€‘çš„åˆ†ææŠ¥å‘Šã€‚
    ã€æ ¸å¿ƒåŸåˆ™ã€‘ï¼š
    1. **æ ¼å¼ä¸¥æ ¼**ï¼šå¿…é¡»ä¸¥æ ¼éµå®ˆç”¨æˆ·ç»™å®šçš„ Markdown ç»“æ„ã€‚
    2. **å±è”½å¼•ç”¨**ï¼šä¸è¦ç”Ÿæˆå‚è€ƒæ–‡çŒ®ç« èŠ‚ã€‚
    3. **æ•°å­¦å…¬å¼**ï¼šè¡Œå†…å…¬å¼ç”¨ $...$ï¼Œç‹¬ç«‹å…¬å¼ç”¨ $$...$$ã€‚
    4. **ä¸­æ–‡æŠ¥å‘Š**ï¼šæŠ¥å‘Šå¿…é¡»æ˜¯ä¸­æ–‡ï¼Œé™¤å¿…è¦çš„è‹±æ–‡æè¿°å¤–ï¼Œå…¶ä»–å†…å®¹å‡éœ€ç”¨ä¸­æ–‡ã€‚
    """

    # 2. å®šä¹‰ User Prompt (å…·ä½“ä»»åŠ¡ + è¾“å…¥å†…å®¹)
    # æ³¨æ„è¿™é‡Œä½¿ç”¨äº† f-string å°† input_text åµŒå…¥è¿›å»
    user_prompt = f"""
    è¯·é˜…è¯»ä»¥ä¸‹è®ºæ–‡å†…å®¹ï¼Œå¹¶æŒ‰ç…§ä¸‹æ–¹çš„ <OUTPUT_TEMPLATE> ç”ŸæˆæŠ¥å‘Šã€‚

    <OUTPUT_TEMPLATE>
    1. **ç»“æ„åŒ–**ï¼šæŠ¥å‘Šå¿…é¡»åŒ…æ‹¬æ ‡é¢˜ã€æ‘˜è¦ã€å¼•è¨€ã€æ–¹æ³•ã€å®éªŒ/ç»“æœã€è®¨è®ºã€ç»“è®ºã€åˆ›æ–°ç‚¹ã€å±€é™æ€§ã€æœªæ¥å·¥ä½œå»ºè®®ï¼Œå±‚çº§ä½¿ç”¨ Markdown æ ‡é¢˜ï¼ˆ#ã€##ã€###ï¼‰æ˜ç¡®åˆ’åˆ†ã€‚
    2. **ä¿¡æ¯å®Œæ•´**ï¼šå¯¹æ¯ä¸€ç« èŠ‚ç»™å‡º **æ¦‚è¦**ï¼ˆ200â€‘300 å­—ï¼‰ã€**å…³é”®æŠ€æœ¯/æ–¹æ³•ç»†èŠ‚**ï¼ˆå…¬å¼ã€ç®—æ³•ã€å®éªŒè®¾è®¡ç­‰ï¼‰ï¼Œå¹¶ç”¨ **è¡¨æ ¼æˆ–åˆ—è¡¨** æ¢³ç†é‡è¦ä¿¡æ¯ã€‚
    3. **æ‰¹åˆ¤æ€§è¯„ä»·**ï¼šä»åˆ›æ–°æ€§ã€ç†è®ºè´¡çŒ®ã€å®éªŒè®¾è®¡ã€ç»“æœå¯ä¿¡åº¦ã€å¯é‡å¤æ€§ã€å®é™…åº”ç”¨ä»·å€¼ç­‰æ–¹é¢ç»™å‡º **ä¼˜ç‚¹** ä¸ **ç¼ºç‚¹**ï¼Œå¹¶æä¾› **æ”¹è¿›å»ºè®®**ã€‚
    4. **å¯è¯»æ€§**ï¼šä½¿ç”¨ **ç®€æ´ã€ä¸“ä¸šçš„è¯­è¨€**ï¼Œé¿å…å†—é•¿ï¼›å…³é”®æ¦‚å¿µç”¨ **ç²—ä½“** æ ‡è®°ï¼›é‡è¦æ•°å­—ã€å…¬å¼æˆ–å®éªŒç»“æœä½¿ç”¨ **ä»£ç å—æˆ– LaTeX** è¿›è¡Œæ¸²æŸ“ã€‚

    ---

    ## ğŸ“Œ è¾“å…¥ä¿¡æ¯ï¼ˆè¯·å®Œæ•´å¡«å†™ï¼‰

    - **è®ºæ–‡æ ‡é¢˜**ï¼š`ã€è®ºæ–‡æ ‡é¢˜ã€‘`
    - **ä½œè€… / æœºæ„**ï¼š`ã€ä½œè€…åˆ—è¡¨ã€‘`
    - **å‡ºç‰ˆå¹´ä»½ / ä¼šè®® / æœŸåˆŠ**ï¼š`ã€å‡ºç‰ˆä¿¡æ¯ã€‘`
    - **DOI / é“¾æ¥**ï¼š`ã€è®ºæ–‡é“¾æ¥æˆ– DOIã€‘`
    - **å…¨æ–‡ï¼ˆå¯ç²˜è´´æˆ–æä¾›é“¾æ¥ï¼‰**ï¼š`ã€è®ºæ–‡å…¨æ–‡æˆ– PDF é“¾æ¥ã€‘`
    - **ç ”ç©¶èƒŒæ™¯ï¼ˆå¯é€‰ï¼‰**ï¼š`ã€è¯¥è®ºæ–‡æ‰€å±é¢†åŸŸçš„ç®€è¦èƒŒæ™¯ã€‘`
    - **é‡ç‚¹å…³æ³¨**ï¼ˆå¯å¤šé€‰ï¼‰ï¼š
    - â˜ æ–¹æ³•åˆ›æ–°
    - â˜ å®éªŒè®¾è®¡
    - â˜ ç†è®ºè¯æ˜
    - â˜ åº”ç”¨ä»·å€¼
    - â˜ ä»£ç å®ç°
    - â˜ å…¶ä»–ï¼ˆè¯·è¯´æ˜ï¼‰`ã€å…³æ³¨ç‚¹ã€‘`

    ---

    ## ğŸ§­ æœŸæœ›è¾“å‡ºï¼ˆMarkdown æŠ¥å‘Šç»“æ„ç¤ºä¾‹ï¼‰

    ```markdown
    # è®ºæ–‡æ ‡é¢˜ï¼š<è®ºæ–‡æ ‡é¢˜>

    **ä½œè€…**ï¼š<ä½œè€…åˆ—è¡¨>
    **å‡ºç‰ˆä¿¡æ¯**ï¼š<ä¼šè®®/æœŸåˆŠ, å¹´ä»½>
    **DOI / é“¾æ¥**ï¼š<é“¾æ¥>

    ---

    ## æ‘˜è¦ (Summary)
    - 150â€‘200 å­—æ¦‚æ‹¬è®ºæ–‡æ ¸å¿ƒè´¡çŒ®ã€æ–¹æ³•ä¸ä¸»è¦ç»“è®ºã€‚

    ## 1. å¼•è¨€ (Introduction)
    - ç ”ç©¶åŠ¨æœºã€èƒŒæ™¯ã€é—®é¢˜å®šä¹‰
    - ä¸ç°æœ‰å·¥ä½œå¯¹æ¯”ï¼ŒæŒ‡å‡ºç ”ç©¶ç©ºç™½

    ## 2. æ–¹æ³• (Methodology)
    ### 2.1 æ¨¡å‹/ç®—æ³•æ¦‚è¿°
    - å…³é”®å…¬å¼ï¼ˆä½¿ç”¨ LaTeXï¼‰
    - ç®—æ³•æµç¨‹å›¾ï¼ˆæ–‡å­—æè¿°æˆ–ä¼ªä»£ç ï¼‰
    ### 2.2 å®ç°ç»†èŠ‚
    - æ•°æ®é¢„å¤„ç†ã€è¶…å‚æ•°è®¾ç½®ã€ç¡¬ä»¶ç¯å¢ƒ

    ## 3. å®éªŒè®¾è®¡ä¸ç»“æœ (Experiments & Results)
    - æ•°æ®é›†ä»‹ç»ï¼ˆè¡¨æ ¼ï¼‰
    - å®éªŒè®¾ç½®ï¼ˆå¯¹æ¯”åŸºçº¿ã€è¯„ä»·æŒ‡æ ‡ï¼‰
    - ç»“æœå±•ç¤ºï¼ˆè¡¨æ ¼ + å›¾è¡¨ï¼‰
    - æ¶ˆèå®éªŒä¸æ•æ„Ÿæ€§åˆ†æ

    ## 4. è®¨è®º (Discussion)
    - ç»“æœè§£è¯»ã€ä¼˜åŠ¿åˆ†æ
    - å±€é™æ€§ä¸æ½œåœ¨åå·®

    ## 5. åˆ›æ–°ç‚¹ (Key Contributions)
    - åˆ—ä¸¾ 3â€‘5 æ¡ï¼Œä½¿ç”¨é¡¹ç›®ç¬¦å·

    ## 6. å±€é™æ€§ä¸æ”¹è¿›å»ºè®® (Limitations & Future Work)
    - æ–¹æ³•å±€é™ã€å®éªŒé™åˆ¶
    - æœªæ¥å¯èƒ½çš„ç ”ç©¶æ–¹å‘

    ## 7. æ€»ç»“
    - ç”¨ä¸€æ®µè¯æ€»ç»“æ–‡ç« çš„å†…å®¹
    </OUTPUT_TEMPLATE>

    ---
    ã€è®ºæ–‡å…¨æ–‡è¾“å…¥ã€‘ï¼š
    {input_text}
    """

    try:
        response = await llm_manager.chat(
            pool_name="analysis",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.2,
            validator=validate_analysis
        )
        logger.info("è¯¦ç»†æŠ¥å‘Šç”ŸæˆæˆåŠŸ")
        return response.choices[0].message.content
    except Exception as e:
        logger.error(f"Analysis ä»»åŠ¡å¤±è´¥: {e}")
        raise e

# ================= æ ¸å¿ƒç¼–æ’ =================

async def process_workflow(pdf_path, file_md5=None, owner_id=None):
    """
    owner_id: å½“å‰ä¸Šä¼ ç”¨æˆ·çš„ ID
    """
    # 1. è§£æ PDF
    workflow_logger.log_start(pdf_path)
    head_text, full_text = extract_pdf_content(pdf_path)
    if not head_text: raise ValueError("PDFè§£æä¸ºç©º")

    # 2. æå–å…ƒæ•°æ® (Metadata)
    workflow_logger.log_step(1, 4, "æå–å…ƒæ•°æ®ä»¥æŸ¥é‡")
    metadata = await task_extract_metadata(head_text)
    
    if not metadata or not metadata.get('title'):
        raise ValueError("å…ƒæ•°æ®æå–å¤±è´¥ï¼Œæ— æ³•æŸ¥é‡")

    # === ğŸ›‘ è¯­ä¹‰æŸ¥é‡ ===
    current_title = metadata.get('title')
    normalized_current = normalize_title(current_title)
    
    session = DBSession()
    try:
        existing_papers = session.query(Paper.title).all()
        for (db_title,) in existing_papers:
            if normalize_title(db_title) == normalized_current:
                workflow_logger.log_skip(pdf_path, f"è¯­ä¹‰é‡å¤: {current_title}")
                raise FileExistsError(f"è¯­ä¹‰é‡å¤: {current_title}")
    finally:
        session.close()

    logger.info("é€šè¿‡æŸ¥é‡ï¼Œå¼€å§‹æ·±åº¦åˆ†æ")
    
    # 3. æ·±åº¦åˆ†æ (Analysis)
    workflow_logger.log_step(2, 4, "æ·±åº¦åˆ†æ")
    analysis = await task_analyze_paper(full_text)

    # 4. å…¥åº“ (å…³è” Owner)
    workflow_logger.log_step(3, 4, "å†™å…¥æ•°æ®åº“")
    session = DBSession()
    try:
        new_paper = Paper(
            md5_hash=file_md5,
            title=metadata.get('title'),
            title_cn=metadata.get('title_cn'),
            journal=metadata.get('journal'),
            year=str(metadata.get('year')),
            authors=metadata.get('authors'),
            abstract_en=metadata.get('abstract_en'),
            abstract=metadata.get('abstract'),
            detailed_analysis=analysis,
            owner_id=owner_id  # <--- è¿™é‡Œå…³è”ç”¨æˆ·
        )
        session.add(new_paper)
        session.commit()
        workflow_logger.log_complete(pdf_path, metadata.get('title', ''))
        
    except Exception as e:
        session.rollback()
        raise e
    finally:
        session.close()
